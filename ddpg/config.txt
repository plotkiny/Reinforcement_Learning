parameters:
    actor_optimizer_fn: None
    beta_frames: 1000
    buffer_size: 1000000
    batch_size: 1024
    critic_optimizer_fn: None
    discount: 0.99
    entropy_weight: 0
    eval_interval: 100000
    gae_tau: 0.001
    gradient_clip: 1
    hidden_layers: [400,300]
    max_steps: 2000
    memory_size: 1024
    multi_agent" False
    n_episodes: 100
    network_fn: None
    num_workers: 1
    optimizer_fn: None
    p_alpha: 0.97
    p_beta: 0.001
    replay_fn: None
    random_process_fn: None
    reward_normalizer: None
    seed: 2
    state_normalizer: True
    tag: "vanilla"
    task_fn: None
    update_every: 3